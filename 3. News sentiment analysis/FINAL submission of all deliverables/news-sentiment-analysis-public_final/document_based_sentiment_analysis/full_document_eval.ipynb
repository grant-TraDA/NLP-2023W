{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_PATH = '../data_preparation/whole_dataset.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T00:07:32.643899Z",
     "start_time": "2023-12-13T00:07:32.629695200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('../lib/sentiment_analysis_utils')\n",
    "sys.path.append('../lib')\n",
    "from sentiment_analysis_utils import combine_lede_and_text, remove_text_formatting, read_all_news_in_dir\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformers_device = 0 if device == 'cuda:0' else -1\n",
    "# print(torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw = pd.read_csv(DATA_PATH)\n",
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:17:33.339988400Z",
     "start_time": "2023-12-12T23:17:32.030010800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load the model below. We decided on siebert at this moment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "models = {\n",
    "    \"siebert-roberta\": pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\", device=transformers_device),\n",
    "    ## labels: 0=neg, 1=pos\n",
    "\n",
    "    \"financial-bert\":  pipeline(\"text-classification\", model=\"ahmedrachid/FinancialBERT-Sentiment-Analysis\", device=transformers_device),\n",
    "    ## labels: 0=neg, 1=neutral, 2=pos\n",
    "\n",
    "    \"auditor_sentiment\": pipeline(\"text-classification\", model=\"FinanceInc/auditor_sentiment_finetuned\", device=transformers_device),\n",
    "    ## labels: 0=neg, 1=neutral, 2=pos\n",
    "\n",
    "    \"twitter-roberta\": pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", device=transformers_device),\n",
    "    ## labels: 0=neg, 1=neutral, 2=pos\n",
    "\n",
    "    \"financial-roberta\": pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\", device=transformers_device)\n",
    "    ## labels: 0=neg, 1=neutral, 2=pos\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to limitation of 512 tokens we need to iterate over 512-token chunks of longer articles. The logits are finally aggregated by mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_article_sentiment(article_text, sentiment_pipeline):\n",
    "    tokens = torch.tensor(sentiment_pipeline.tokenizer.encode(article_text)).unsqueeze(0)\n",
    "    max_tokens = min(sentiment_pipeline.tokenizer.model_max_length, 512)\n",
    "    n_iter = tokens.shape[1] // max_tokens + 1\n",
    "    logits = []\n",
    "    # iterate over [max_tokens]-token chunks of the article\n",
    "    for i in range(n_iter):\n",
    "        current_tokens = tokens[:,i*max_tokens:(i+1)*max_tokens]\n",
    "        if current_tokens.shape[1] == 0:\n",
    "            break\n",
    "        current_attention = torch.ones_like(current_tokens)\n",
    "        # get prediction of current chunk of the article\n",
    "        logits += [sentiment_pipeline.model(input_ids=current_tokens, attention_mask=current_attention).logits]\n",
    "    # aggregate results of chunks by mean\n",
    "    softmax = torch.cat(logits).mean(0).softmax(0)\n",
    "    if len(softmax) == 2:\n",
    "        if softmax[0] < 0.5:\n",
    "            return 1 # neutral\n",
    "        else:\n",
    "            return 2 * softmax.argmax().item() # 2 * {0, 1} -> 2 is positive, 0 is negative\n",
    "    return softmax.argmax().item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:06:09.431994300Z",
     "start_time": "2024-01-16T22:06:09.408197800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check for one article"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = df_en_raw.text[21]\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:06:11.237135600Z",
     "start_time": "2024-01-16T22:06:11.174139200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"model: {name} predicted {predict_article_sentiment(text, model)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T22:06:43.734235400Z",
     "start_time": "2024-01-16T22:06:18.099536800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(os.path.join('..', 'data_preparation', 'testset.csv'), index_col=0)\n",
    "# for i, row in tqdm(test_df.iterrows()):\n",
    "#     test_df.loc[i, 'overall_sentiment'] = predict_article_sentiment(row.whole_text, sentiment_analysis)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T00:10:50.921615100Z",
     "start_time": "2023-12-13T00:10:26.814105500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test_df.to_csv(\"test_df_overall_sentiment.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T00:18:24.891464900Z",
     "start_time": "2023-12-13T00:18:24.782095100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full data evaluation\n",
    "\n",
    "Make predicitons and save the file at the end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    for i, row in tqdm(df_en_raw.iterrows()):\n",
    "        df_en_raw.loc[i, 'overall_sentiment_name'] = predict_article_sentiment(row.whole_text, model)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            df_en_raw.to_csv(f\"full_dataseet_overall_sentiment_{name}_{i}.csv\")\n",
    "\n",
    "    df_en_raw.to_csv(f\"full_dataseet_overall_sentiment_{name}.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-13T00:19:37.235966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
