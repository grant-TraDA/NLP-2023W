{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook used for data preprocessing. Using predefined functions, this notebook prepares texts of articles for ML tasks we perform."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification, pipeline\n",
    "from lib.sentiment_analysis_utils import combine_lede_and_text, remove_text_formatting, read_all_news_in_dir\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw = read_all_news_in_dir(os.getcwd() + \"/../data_preparation/raw_data/en/\")\n",
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw = combine_lede_and_text(df_en_raw)\n",
    "df_en_raw = remove_text_formatting(df_en_raw)\n",
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform preprocessing using functions from lib. Lede and remaining text of article are firstly combined. Then text formatting is removed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw = df_en_raw[df_en_raw['whole_text']!='']\n",
    "df_en_raw = df_en_raw.drop_duplicates(subset=['whole_text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop duplicates and articles which text is empty."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df_en_raw = df_en_raw.join(pd.DataFrame(mlb.fit_transform(df_en_raw.categories),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df_en_raw.index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use MultiLabelBinarizer to extract categories into separate columns which will allow sampling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For English, there are nine categories:\n",
    "  - Advisory - AD\n",
    "  - Arts and Culture - AC\n",
    "  - Around Slovenia - AS\n",
    "  - Business, finance and economy - BE\n",
    "  - Health, environment, science - HE\n",
    "  - Politics - PO\n",
    "  - Roundup - RU\n",
    "  - Schedule of Events - SE\n",
    "  - Sports - ST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "authors = set()\n",
    "for i, row in df_en_raw.iterrows():\n",
    "    tmp = row.byline.split('/')\n",
    "    for author in tmp:\n",
    "        authors.add(author)\n",
    "\n",
    "print(authors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "extracting authors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=model_ner, tokenizer=tokenizer_ner, grouped_entities=True, device=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we have decided to use Babelscape/wikineural-multilingual-ner model as it gave the most promising preliminary results. Mainly as it firstly allowed for grouped entities. (Entities with names composed of multiple words). Secondly, it was multilingual and trained on large corpora. Even though Slovenian was not among the languages it was trained on, having other than English languages helped. Even though articles are in English, naturally there are slovenian entities mentioned quite often. We believe that training on multiple languages still allowed for more accurate assessment when non-English entity was mentioned. (This model was the most sensitive returning on average the most entities, whereas other had tendency to omit some of the entities. + returned names were actually entities.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, row in df_en_raw.iterrows():\n",
    "    ner_results = ner_pipeline(row.whole_text)\n",
    "    ner_list = set([result['word'] for result in ner_results])\n",
    "\n",
    "    df_en_raw.at[i, 'ner_list'] = ''\n",
    "    df_en_raw.at[i, 'ner_list'] = list(ner_list)\n",
    "\n",
    "    keywords_lower = [keyword.lower() for keyword in row.keywords]\n",
    "    df_en_raw.at[i, 'keywords_lower'] = ''\n",
    "    df_en_raw.at[i, 'keywords_lower'] = keywords_lower"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Producing the lists of ners and embedding them. keywords are turned to lowercase."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_en_raw.to_csv('whole_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving preprocessed data into single csv file. This can be used to perform document based and abstract based sentiment analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
